\input{header.tex}

\begin{document}
\renewcommand{\f}{\mathbb{f}}

\section{Лекция 28 от 19.04.2016}

\par Пусть $V$ --- векторное пространство над полем $F$ размерности $n$. $\mathbb{e} = (e_1, \ldots, e_n)$ --- его базис.
\par $Q\colon \; V \to F$ --- квадратичная форма.
\par $\beta\colon\; V\times V \to F$ --- билинейная функция.
\par $B = B(\beta, \mathbb{e})$. $B_i$ --- левая верхняя $i\times i$-подматрица.\\
$B = \begin{pmatrix}
	b_{11}& b_{12} & b_{13} & \vdots\\
	b_{21}& b_{22} & b_{23} & \vdots\\
	b_{31}& b_{32}& b_{33} & \vdots\\
	\cdots& \cdots& \cdots& \ddots
\end{pmatrix}$
В такой матрице $B_1 = (b_{11})$, $B_2 = \begin{pmatrix}
	b_{11}& b_{12}\\
	b_{21}& b_{22}
\end{pmatrix}$
и так далее...
\par Матрица $B_i$ --- это матрица ограничения билинейной функции $\beta$ на подпространство, натянутое на векторы $(e_1, \ldots, e_i)$. Введём обозначения $\delta_i = \det(B_i)$. Принято также, что $\delta_0 = 1$. 
\begin{Def}
	Базис $\mathbb{e}$ называется ортогональным, если $\forall i\neq j$ $\beta(e_i, e_j) = 0$. В ортогональном базисе матрица квадратичной формы имеет канонический вид.
\end{Def}
\begin{Theorem}[Метод ортогонализации Грамма -- Шмидта]
		Предположим, что $\delta_i \neq 0 \forall i$. Тогда $\exists ! \mathbb{e}' = (e_1', \ldots, e_n')$ в $V$ такой, что
		\begin{enumerate}
			\item $\mathbb{e}'$ --- ортогональный
			\item $e_1' = e_1,\\ e_2' \in e_2 + \langle e_1'\rangle,\\ e_3' \in  e_3 + \langle e_1', e_2' \rangle,\\ \ldots\\ e_n' \in  e_n + \langle e_1', \ldots, e_{n-1}'\rangle$
			\item В новом базисе $Q(e_i') = \cfrac{\delta_i}{\delta_{i-1}}\forall i$
		\end{enumerate}	
\end{Theorem}
\begin{proof}
	Индукция по $n$. База для $n = 1$ всё очевидно. 
	\par Теперь пусть всё доказано для всех $k<n$. Докажем для $n$. По предположению индукции $\exists !\; (e_1', e_2', \ldots, e_n')$ с требуемыми свойствами. Наблюдение: $\langle e_i, \ldots, e_n\rangle = \langle e_i', \ldots, e_n'\rangle$. Ищем $e_n'$ в виде $e_n' = e_n + \lambda_1 e_1' + \ldots + \lambda_{n-1}e_{n-1}'$
	\[
 \beta(e_n', e_1') = \beta(e_n, e_i) + \sum\limits^{n}_{j = 1} \lambda_j\beta (e_j', e_i')	\;\forall i=1,\ldots, n-1\
	\]
	Последнее слагаемое обращается в нуль при $i \neq j$.
	\[
		0 = \beta(e_n, e_i') + \lambda_i \beta(e_i', e_j')= \beta(e_n, e_i') + Q(e_i) = \beta(e_n, e_i') + \underbrace{\cfrac{\delta_i}{\delta_{i - 1}}}_{\neq 0}
	\]
	Выбирая $\lambda_n = -\cfrac{\beta(e_n, e_i')}{\beta(e_i', e_i')}$ получаем однозначность. Таким образом, условия 1 и 2 выполнены. Проверим условие 3. Пусть $C$ --- матрица перехода от $\mathbb{e}$ к $\mathbb{e}'$. Тогда легко понять, что $C$ --- верхнетреугольная с 1 на главной диагонали. Значит $B' = C^{T}BC$ --- диагональная. Заметим также, что $C_i$ (та самая верхняя $i\times i$ подматрица) --- матрица перехода от $(e_1, \ldots, e_i)$ к $(e_1', \ldots, e_i')$. Тогда
	\[
		B_i' = C_i^TB_iC_i \Rightarrow \det B_i' = 1\cdot \det(B_i) \cdot 1 = \delta_i
	\]
	Но поскольку $B' = \begin{pmatrix}
		Q(e_1')& \ & \ \\
		 \ & \ddots& \  \\
		 \ &\ & Q(e_n')
	\end{pmatrix}$, то $\delta_n = Q(e_1')\ldots Q(e_n')$. А значит $\cfrac{\delta_n}{\delta_{n-1}} = Q(e_n')$.
\end{proof}
Если $F = \mathbb{R}$.
\begin{Theorem}[Якоби]
	Пусть $\delta_i \neq 0\; \forall i$. Тогда $\mathrm{rk}\; Q = n$, $i_{-}(Q)$ равен числу перемен знака последовательности $1, \delta_1, \ldots, \delta_n$.
\end{Theorem}
\begin{proof}
	Применим процесс ортогонализации $\exists (e_1', \ldots, e_n')$, в котором $\cfrac{\delta_1}{\delta_0}y_1^2 +\ldots + \cfrac{\delta_n}{\delta_{n-1}} < 0$. А это верно тогда и только тогда, когда $\forall i\; \delta_i, \delta_{i-1}$ имеют разные знаки.
\end{proof}
\begin{Theorem}[Критерий Сильвестра]
	$Q > 0 \Leftrightarrow \delta_i > 0 \forall i = 1,\ldots, n$.
\end{Theorem}
\begin{proof}
	$[\Leftarrow]$ --- следует из предыдущей теоремы. \\
	$[\Rightarrow]$. Докажем, чтo $\delta_i = \det(B_i) > 0$. Действительно, $B_i$ --- это матрица ограничения\\ $Q\bigr|_{\langle e_1, \ldots, e_i\rangle} > 0$. $\exists С_i \in M_n(\mathbb{R}), \det(C_i) \neq 0$, такая, что $C_i^TBC_i = E$. \\
	$\det C^T_i\det B_i \det C_i = 1 \Rightarrow \det B_i = \cfrac{1}{(\det C_i)^2}$
\end{proof}
\begin{Theorem}
	 $Q > 0 \Leftrightarrow \begin{cases}
		\delta_i < 0,\ i = 2k + 1,\; k\in \mathbb{Z}\\
		\delta_i > 0,\ i = 2k,\; k \in \mathbb{Z}
	\end{cases}$
\end{Theorem}
\begin{proof}
	Применяя критерий Сильвестра для $B(Q, \mathbb{e}) = - B(-Q, \mathbb{e})$, получаем требуемое
\end{proof}
\subsection*{Евклидовы пространства}

\begin{Def}
	$\mathbb{E} $ --- векторное пространство над $\mathbb{R}$, на котором задана положительно определённая симметрическая билинейная функция $(\cdot, \cdot)$, (которую в дальлнейшем будем называть скалярным произведением)
\end{Def}
\begin{Examples}
	$\mathbb{R}^n, x = \begin{pmatrix}x_1\\ \vdots\\ x_n\end{pmatrix}$, $y = \begin{pmatrix}y_1\\ \vdots\\ y_n\end{pmatrix}$
	\[
		(x,y) = \sum\limits_{i = 1}^n x_iy_i
	\]
\end{Examples}
\begin{Comment}
	Важно отметить, что евклидово пространство можно определить только над полем $\mathbb{R}$.
\end{Comment}
\begin{Def}
	$x\in \mathbb{E}$. Тогда длиной вектора называют величину $|x| = \sqrt{(x,x)}$.
\end{Def}
\begin{Suggestion}[Неравенство Коши-Буняковского]
	$|(x,y)| \leqslant |x||y|$, причём знак равенства возможен тогда и только тогда, когда $x$ и $y$ пропорциональны.
\end{Suggestion}
\begin{proof}
	\ \\
	\begin{enumerate}
		\item $x,y$ пропорциональны, т.е. $x = \lambda y$ для некоторого $\lambda$. Тогда
		\[
			|(x,y)| = |(x,\lambda x)| = \lambda|(x,x)| = |x|\lambda|x| = |x||y|
		\]
		\item $x,y$ линейно независимы. Тогда они будут базисом своей линейной оболочки. Тогда матрица билинейной функции $(\cdot, \cdot)$ равна
		\begin{gather*}
		B = \begin{pmatrix}
			(x,x)& (x,y)\\
			(y,x)& (y,y)
		\end{pmatrix}\\
		\det B >0 \Rightarrow (x,x)(y,y) - (x,y)^2 > 0\\
		|(x,y)| < |x|^2|y|^2\\
		|(x,y)| < |x||y|
		\end{gather*}
		
	\end{enumerate}
\end{proof}
\begin{Def}
	Углом между векторами $x,y$ называют $\arccos \cfrac{(x,y)}{|x||y|}$
\end{Def}
Пусть есть система векторов $(v_1, \ldots, v_k)$.
\begin{Def}[Матрица Грама]
	$G(v_1,\ldots, v_k) = (g_{ij}), g_{ij} = (v_i,v_j)$
\end{Def}
\begin{Suggestion}
	\begin{enumerate}
		\item $\det G(v_1, \ldots, v_k) \geqslant 0$
		\item $\det G(v_1, \ldots, v_k) = 0$ тогда и только тогда, когда $v_1, \ldots, v_k$ линейно зависимы.
	\end{enumerate}
\end{Suggestion}
\begin{proof}
	\ \\
	\begin{enumerate}
		\item $v_1, \ldots, v_k$ линейно независимы. Следовательно матрица $G(v_1, \ldots, v_k)$ является матрицей ограничения $(\cdot, \cdot)$ на $\langle v_1, \ldots, v_k\rangle$, в котором базисом является $(v_1, \ldots, v_k)$. А значит $\det G(v_1, \ldots, v_k) > 0$.
		\item $v_1, \ldots, v_k$  линейно зависимы. Значит
		\begin{gather*}
			\lambda_1 G_{(1)} + \lambda_2 G_{(2)} + \ldots + \lambda_k G_{(k)} =\\= ((\lambda_1v_1 + \lambda_2 v_2 + \ldots + \lambda_kv_k, v_1),(\lambda_1v_1 + \lambda_2 v_2 + \ldots + \lambda_kv_k, v_2), \ldots ,(\lambda_1v_1 + \lambda_2 v_2 + \ldots + \lambda_kv_k, v_k) = \\
			= (0, 0, \ldots 0)
		\end{gather*}
		То есть строки линейно зависимы и $\det G = 0$.
	\end{enumerate}
\end{proof}
\end{document}